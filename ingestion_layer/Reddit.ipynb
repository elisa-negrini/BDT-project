{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44936b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Configura le tue credenziali Reddit\n",
    "client_id = 'XpeJWmueFBEGkyXjE-dpcA'\n",
    "client_secret = 'yOyCLHaB0Ur7R0sW75UUmc20MjCPkw'\n",
    "user_agent = 'Samu_Miki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f02944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per ottenere un token\n",
    "def get_reddit_token(client_id, client_secret, user_agent):\n",
    "    url = 'https://www.reddit.com/api/v1/access_token'\n",
    "    headers = {\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials'\n",
    "    }\n",
    "    auth = (client_id, client_secret)\n",
    "    \n",
    "    # Fai la richiesta per ottenere il token\n",
    "    response = requests.post(url, headers=headers, data=data, auth=auth)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        token = response.json()['access_token']\n",
    "        print(f'Token ottenuto con successo: {token}')\n",
    "        return token\n",
    "    else:\n",
    "        print(f'Errore durante l\\'ottenimento del token: {response.status_code}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3ea9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per fare una richiesta con paramentro top all'API Reddit\n",
    "def get_reddit_posts(token):\n",
    "    url = 'https://oauth.reddit.com/r/stocks/top?t=week&limit=100'\n",
    "    headers = {\n",
    "        'Authorization': f'bearer {token}',\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "    \n",
    "    # Fai la richiesta per ottenere i post    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Estrai i post\n",
    "        posts = data['data']['children']\n",
    "        \n",
    "        # Crea una lista di dizionari con le informazioni che ti interessano\n",
    "        posts_list = []\n",
    "        for post in posts:\n",
    "            post_data = post['data']\n",
    "            posts_list.append({\n",
    "                'id': post_data.get('id'),\n",
    "                'title': post_data.get('title'),\n",
    "                'author': post_data.get('author'),\n",
    "                'score': post_data.get('score'),\n",
    "                'num_comments': post_data.get('num_comments'),\n",
    "                'created_utc': post_data.get('created_utc'),\n",
    "                'permalink': post_data.get('permalink'),\n",
    "                'url': post_data.get('url'),\n",
    "                'subreddit': post_data.get('subreddit')\n",
    "            })\n",
    "\n",
    "        # Crea il DataFrame\n",
    "        df_reddit = pd.DataFrame(posts_list)\n",
    "        df_reddit['created_datetime'] = pd.to_datetime(df_reddit['created_utc'], unit='s')\n",
    "        \n",
    "        print(f'Recuperati {len(df_reddit)} post.')\n",
    "        return df_reddit\n",
    "    \n",
    "    else:\n",
    "        print(f'Errore durante la richiesta ai post: {response.status_code}')\n",
    "        return pd.DataFrame()  # ritorna un df vuoto in caso di errore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "837e953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ottenuto con successo: eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJsb2lkIiwiZXhwIjoxNzQ2MzY2MDcwLjUwMTgxLCJpYXQiOjE3NDYyNzk2NzAuNTAxODEsImp0aSI6IlJTeHpkREp4V0dGV2ZuSmNpYUphd204RFhrSWpXQSIsImNpZCI6IlhwZUpXbXVlRkJFR2t5WGpFLWRwY0EiLCJsaWQiOiJ0Ml8xb2xucndlbHg3IiwibGNhIjoxNzQ2Mjc5NjcwNDg3LCJzY3AiOiJlSnlLVnRKU2lnVUVBQURfX3dOekFTYyIsImZsbyI6Nn0.IRTyS6YsTwNFaZx3lQF_ysdGTWrWue7cC1GlxSGKw0JtUDpuiAfUVfrN9SqOfADKN29t1O_L5_R1Aaju4lq3aCAPVbvnuHbX39YcjipARhDKPqO9Pu1k_Nb_eZ_3S_jNLaSdT_ljHee722FIs1kztmZH2beJynb6LVryPfFk4tnZNS2OeQ4ZDI5GLle8ipPaCVEgWyVGY-TX686m1hZ3QmkbU-k-aU7FCkJNQVIVb8RAcnaJ1qF_sZ3XHKvPhXS_XlOZVB8SGbvcNki2n-AnekiyHSpa2sJy2rsZ4U79V_QH8_DQKGuBX1GdBVP8qBkX_DVITitCm9-I-rXKlFwEjw\n"
     ]
    }
   ],
   "source": [
    "#ottenere il token:\n",
    "token = get_reddit_token(client_id, client_secret, user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e4f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ottenuto con successo: eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJsb2lkIiwiZXhwIjoxNzQ2MzY2MDcwLjczMDcwMiwiaWF0IjoxNzQ2Mjc5NjcwLjczMDcwMiwianRpIjoibzV6NWlSSUVqZjZyZC1KU1JXSHNINnNSaXF4YXFnIiwiY2lkIjoiWHBlSldtdWVGQkVHa3lYakUtZHBjQSIsImxpZCI6InQyXzFvbG5yd2cyMmoiLCJsY2EiOjE3NDYyNzk2NzA3MTUsInNjcCI6ImVKeUtWdEpTaWdVRUFBRF9fd056QVNjIiwiZmxvIjo2fQ.ORd_uD01tYVBjNsnxYoB6niBK9gGO_ANwU0xDHBF82gMbOGf7ylOLmBfhuN_3i-spObT5ejoZwKRaDs7cqrSvDn4FXQPT6xpEDYEjp_kZLsvnVnlOqL7TuspDLXJHgyX8eVAt-BG3eDHY-cW90wAGz9Kbc16yFk5G7Hc-bMKyvOXqNMLKAhNtAqqNv_s1wrmrE2QavT1dMBTzSA0yK43gQmRJEp1B2dV83x5g3qi49vtdrzb3gSEurfRM0TNCDyAmOVrHOlZ2FjQUxexhHU1GMzXwE2xfvPv4uG5ssGSUumkymBGSSQcJA3mqxgeGQqm2GETnOv1pysiA144M-gHtQ\n",
      "Recuperati 100 post.\n",
      "Aspetta 24 ore per ottenere un nuovo token...\n"
     ]
    }
   ],
   "source": [
    "# PER ORA NON USARE, SERVE PER AVERNE UNO AL GIORNO, PER INTANTO LO FACCIAMO MANUALMENTE CON I COMANDI SOPRA\n",
    "\n",
    "# Ciclo per ottenere e usare il token ogni giorno\n",
    "while True:\n",
    "    # Ottieni il token (scade dopo 24 ore)\n",
    "    token = get_reddit_token(client_id, client_secret, user_agent)\n",
    "    \n",
    "    if token:\n",
    "        # Usa il token per fare la richiesta all'API\n",
    "        get_reddit_posts(token)\n",
    "    \n",
    "    # Aspetta 24 ore (86400 secondi) prima di ottenere un nuovo token\n",
    "    print('Aspetta 24 ore per ottenere un nuovo token...')\n",
    "    time.sleep(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d22b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperati 100 post.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1k6pihz</td>\n",
       "      <td>Now we know. It was Retail CEOS who got to Tru...</td>\n",
       "      <td>Epicurus-fan</td>\n",
       "      <td>47508</td>\n",
       "      <td>2930</td>\n",
       "      <td>1.745493e+09</td>\n",
       "      <td>/r/stocks/comments/1k6pihz/now_we_know_it_was_...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k6pi...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-24 11:09:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1k75t88</td>\n",
       "      <td>Fox Reporter Says the Trump White House Is Giv...</td>\n",
       "      <td>GaussInTheHouse</td>\n",
       "      <td>45042</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.745535e+09</td>\n",
       "      <td>/r/stocks/comments/1k75t88/fox_reporter_says_t...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k75t...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-24 22:51:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1kadl0p</td>\n",
       "      <td>China Officially Makes Statement Stating That ...</td>\n",
       "      <td>Onnimation</td>\n",
       "      <td>34149</td>\n",
       "      <td>2535</td>\n",
       "      <td>1.745894e+09</td>\n",
       "      <td>/r/stocks/comments/1kadl0p/china_officially_ma...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kadl...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 02:40:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1k5g9yj</td>\n",
       "      <td>Tesla reports disappointing quarterly results ...</td>\n",
       "      <td>Puginator</td>\n",
       "      <td>13938</td>\n",
       "      <td>985</td>\n",
       "      <td>1.745353e+09</td>\n",
       "      <td>/r/stocks/comments/1k5g9yj/tesla_reports_disap...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k5g9...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-22 20:13:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1k9vrt4</td>\n",
       "      <td>Agriculture isn't nearing trade war tariffs cr...</td>\n",
       "      <td>AssociateGreat2350</td>\n",
       "      <td>10086</td>\n",
       "      <td>923</td>\n",
       "      <td>1.745848e+09</td>\n",
       "      <td>/r/stocks/comments/1k9vrt4/agriculture_isnt_ne...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k9vr...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-28 13:39:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1k8t08k</td>\n",
       "      <td>Which of these is not like the others?</td>\n",
       "      <td>30030s</td>\n",
       "      <td>118</td>\n",
       "      <td>59</td>\n",
       "      <td>1.745719e+09</td>\n",
       "      <td>/r/stocks/comments/1k8t08k/which_of_these_is_n...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k8t0...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-27 01:55:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1k9yuu7</td>\n",
       "      <td>China‚Äôs Huawei Develops New AI Chip, Seeking t...</td>\n",
       "      <td>SPXQuantAlgo</td>\n",
       "      <td>111</td>\n",
       "      <td>72</td>\n",
       "      <td>1.745855e+09</td>\n",
       "      <td>/r/stocks/comments/1k9yuu7/chinas_huawei_devel...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k9yu...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-28 15:49:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1k94qpa</td>\n",
       "      <td>Is anyone else looking at Goodyear stock?</td>\n",
       "      <td>Cloudbb333</td>\n",
       "      <td>88</td>\n",
       "      <td>62</td>\n",
       "      <td>1.745763e+09</td>\n",
       "      <td>/r/stocks/comments/1k94qpa/is_anyone_else_look...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k94q...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-27 14:05:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1k7yuoj</td>\n",
       "      <td>So how does the lowered regulation for autonom...</td>\n",
       "      <td>zitrored</td>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "      <td>1.745623e+09</td>\n",
       "      <td>/r/stocks/comments/1k7yuoj/so_how_does_the_low...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k7yu...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-25 23:20:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1ka8l67</td>\n",
       "      <td>Stock market today: Dow, S&amp;amp;P 500 erase sli...</td>\n",
       "      <td>Amehoelazeg</td>\n",
       "      <td>77</td>\n",
       "      <td>13</td>\n",
       "      <td>1.745880e+09</td>\n",
       "      <td>/r/stocks/comments/1ka8l67/stock_market_today_...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1ka8l...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-28 22:32:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0   1k6pihz  Now we know. It was Retail CEOS who got to Tru...   \n",
       "1   1k75t88  Fox Reporter Says the Trump White House Is Giv...   \n",
       "2   1kadl0p  China Officially Makes Statement Stating That ...   \n",
       "3   1k5g9yj  Tesla reports disappointing quarterly results ...   \n",
       "4   1k9vrt4  Agriculture isn't nearing trade war tariffs cr...   \n",
       "..      ...                                                ...   \n",
       "95  1k8t08k             Which of these is not like the others?   \n",
       "96  1k9yuu7  China‚Äôs Huawei Develops New AI Chip, Seeking t...   \n",
       "97  1k94qpa          Is anyone else looking at Goodyear stock?   \n",
       "98  1k7yuoj  So how does the lowered regulation for autonom...   \n",
       "99  1ka8l67  Stock market today: Dow, S&amp;P 500 erase sli...   \n",
       "\n",
       "                author  score  num_comments   created_utc  \\\n",
       "0         Epicurus-fan  47508          2930  1.745493e+09   \n",
       "1      GaussInTheHouse  45042          1062  1.745535e+09   \n",
       "2           Onnimation  34149          2535  1.745894e+09   \n",
       "3            Puginator  13938           985  1.745353e+09   \n",
       "4   AssociateGreat2350  10086           923  1.745848e+09   \n",
       "..                 ...    ...           ...           ...   \n",
       "95              30030s    118            59  1.745719e+09   \n",
       "96        SPXQuantAlgo    111            72  1.745855e+09   \n",
       "97          Cloudbb333     88            62  1.745763e+09   \n",
       "98            zitrored     86            60  1.745623e+09   \n",
       "99         Amehoelazeg     77            13  1.745880e+09   \n",
       "\n",
       "                                            permalink  \\\n",
       "0   /r/stocks/comments/1k6pihz/now_we_know_it_was_...   \n",
       "1   /r/stocks/comments/1k75t88/fox_reporter_says_t...   \n",
       "2   /r/stocks/comments/1kadl0p/china_officially_ma...   \n",
       "3   /r/stocks/comments/1k5g9yj/tesla_reports_disap...   \n",
       "4   /r/stocks/comments/1k9vrt4/agriculture_isnt_ne...   \n",
       "..                                                ...   \n",
       "95  /r/stocks/comments/1k8t08k/which_of_these_is_n...   \n",
       "96  /r/stocks/comments/1k9yuu7/chinas_huawei_devel...   \n",
       "97  /r/stocks/comments/1k94qpa/is_anyone_else_look...   \n",
       "98  /r/stocks/comments/1k7yuoj/so_how_does_the_low...   \n",
       "99  /r/stocks/comments/1ka8l67/stock_market_today_...   \n",
       "\n",
       "                                                  url subreddit  \\\n",
       "0   https://www.reddit.com/r/stocks/comments/1k6pi...    stocks   \n",
       "1   https://www.reddit.com/r/stocks/comments/1k75t...    stocks   \n",
       "2   https://www.reddit.com/r/stocks/comments/1kadl...    stocks   \n",
       "3   https://www.reddit.com/r/stocks/comments/1k5g9...    stocks   \n",
       "4   https://www.reddit.com/r/stocks/comments/1k9vr...    stocks   \n",
       "..                                                ...       ...   \n",
       "95  https://www.reddit.com/r/stocks/comments/1k8t0...    stocks   \n",
       "96  https://www.reddit.com/r/stocks/comments/1k9yu...    stocks   \n",
       "97  https://www.reddit.com/r/stocks/comments/1k94q...    stocks   \n",
       "98  https://www.reddit.com/r/stocks/comments/1k7yu...    stocks   \n",
       "99  https://www.reddit.com/r/stocks/comments/1ka8l...    stocks   \n",
       "\n",
       "      created_datetime  \n",
       "0  2025-04-24 11:09:27  \n",
       "1  2025-04-24 22:51:38  \n",
       "2  2025-04-29 02:40:04  \n",
       "3  2025-04-22 20:13:09  \n",
       "4  2025-04-28 13:39:05  \n",
       "..                 ...  \n",
       "95 2025-04-27 01:55:47  \n",
       "96 2025-04-28 15:49:50  \n",
       "97 2025-04-27 14:05:59  \n",
       "98 2025-04-25 23:20:31  \n",
       "99 2025-04-28 22:32:06  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reddit_posts(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f797355",
   "metadata": {},
   "source": [
    "Il parametro \"top\" ci permette di usare un parametro temporale, ma ne ranna davvero pochi (es: se metto hour me ne d√† 2), forse conviene usare il parametro \"new\" e continuare a runnarlo ogni tot, e semmai fare uno script per sistemare. es: prende i dati ogni 10 secondi, e ne prende 100, se 10 secondi dopo rirunniamo e 20 post sono uguali, lui si accorge che sono uguali e tiene solo gli altri 80, lo stesso si pu√≤ fare per l'API di finnhub news che mi d√† le news solo giornalmente, per non doverlo runnare solo una volta al giorno. Usando \"After\" si possono prendere veramente molti dati, perch√® prende la pagina successiva. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggiunti 100 nuovi post.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "all_posts = pd.DataFrame()\n",
    "seen_ids = set()\n",
    "\n",
    "market = [\"stocks\", \"investment\", \"wallstreetbets\", \"StockMarket\", \"financialindependence\"]\n",
    "geopolitics = [\"geopolitics\",\"politics\", \"worldnews\", \"news\", \"Economics\"]\n",
    "\n",
    "def get_new_reddit_posts(token):\n",
    "    url = 'https://oauth.reddit.com/r/stocks/new?limit=100'\n",
    "    headers = {\n",
    "        'Authorization': f'bearer {token}',\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        posts = data['data']['children']\n",
    "        posts_list = []\n",
    "\n",
    "        for post in posts:\n",
    "            post_data = post['data']\n",
    "            if post_data.get('id') not in seen_ids:\n",
    "                seen_ids.add(post_data.get('id'))\n",
    "                posts_list.append({\n",
    "                    'id': post_data.get('id'),\n",
    "                    'title': post_data.get('title'),\n",
    "                    'author': post_data.get('author'),\n",
    "                    'selftext': post_data.get('selftext', ''),\n",
    "                    'score': post_data.get('score'),\n",
    "                    'num_comments': post_data.get('num_comments'),                \n",
    "                    'created_utc': post_data.get('created_utc'),\n",
    "                    'permalink': post_data.get('permalink'),\n",
    "                    'url': post_data.get('url'),\n",
    "                    'subreddit': post_data.get('subreddit')\n",
    "                })\n",
    "\n",
    "        df_new = pd.DataFrame(posts_list)\n",
    "        if not df_new.empty:\n",
    "            df_new['created_datetime'] = pd.to_datetime(df_new['created_utc'], unit='s')\n",
    "            print(f'Aggiunti {len(df_new)} nuovi post.')\n",
    "        else:\n",
    "            print('Nessun nuovo post trovato.')\n",
    "\n",
    "        return df_new\n",
    "    else:\n",
    "        print(f'Errore nella richiesta: {response.status_code}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Esegui il polling ogni 30 secondi\n",
    "for i in range(6):  # ad esempio per 3 minuti\n",
    "    df = get_new_reddit_posts(token)\n",
    "    all_posts = pd.concat([all_posts, df], ignore_index=True)\n",
    "    time.sleep(30)\n",
    "\n",
    "# Salva alla fine o elabora\n",
    "all_posts.drop_duplicates(subset='id', inplace=True)\n",
    "print(f'Totale post raccolti: {len(all_posts)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c61077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1kapihd</td>\n",
       "      <td>The White House confirmed plans for the Trump ...</td>\n",
       "      <td>lionpenguin88</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>1.745937e+09</td>\n",
       "      <td>/r/stocks/comments/1kapihd/the_white_house_con...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kapi...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 14:37:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1kapflz</td>\n",
       "      <td>Buy/sell types and execution during pre, exten...</td>\n",
       "      <td>4G0T2FLU5H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.745937e+09</td>\n",
       "      <td>/r/stocks/comments/1kapflz/buysell_types_and_e...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kapf...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 14:34:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1kap42w</td>\n",
       "      <td>UPS to cut 20,000 jobs on lower Amazon shipmen...</td>\n",
       "      <td>joe4942</td>\n",
       "      <td>94</td>\n",
       "      <td>20</td>\n",
       "      <td>1.745936e+09</td>\n",
       "      <td>/r/stocks/comments/1kap42w/ups_to_cut_20000_jo...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kap4...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 14:20:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1kaoyc1</td>\n",
       "      <td>Barrons: Why Trump‚Äôs Next 100 Days Will Be Mor...</td>\n",
       "      <td>WantedtoRetireEarly</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>1.745936e+09</td>\n",
       "      <td>/r/stocks/comments/1kaoyc1/barrons_why_trumps_...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kaoy...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 14:13:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1kanyf3</td>\n",
       "      <td>Trump Slams Amazon's Tariff Labeling as ‚ÄòHosti...</td>\n",
       "      <td>eteplirsen</td>\n",
       "      <td>8106</td>\n",
       "      <td>849</td>\n",
       "      <td>1.745933e+09</td>\n",
       "      <td>/r/stocks/comments/1kanyf3/trump_slams_amazons...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kany...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 13:29:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  1kapihd  The White House confirmed plans for the Trump ...   \n",
       "1  1kapflz  Buy/sell types and execution during pre, exten...   \n",
       "2  1kap42w  UPS to cut 20,000 jobs on lower Amazon shipmen...   \n",
       "3  1kaoyc1  Barrons: Why Trump‚Äôs Next 100 Days Will Be Mor...   \n",
       "4  1kanyf3  Trump Slams Amazon's Tariff Labeling as ‚ÄòHosti...   \n",
       "\n",
       "                author  score  num_comments   created_utc  \\\n",
       "0        lionpenguin88     33            15  1.745937e+09   \n",
       "1           4G0T2FLU5H      3             0  1.745937e+09   \n",
       "2              joe4942     94            20  1.745936e+09   \n",
       "3  WantedtoRetireEarly     19            13  1.745936e+09   \n",
       "4           eteplirsen   8106           849  1.745933e+09   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/stocks/comments/1kapihd/the_white_house_con...   \n",
       "1  /r/stocks/comments/1kapflz/buysell_types_and_e...   \n",
       "2  /r/stocks/comments/1kap42w/ups_to_cut_20000_jo...   \n",
       "3  /r/stocks/comments/1kaoyc1/barrons_why_trumps_...   \n",
       "4  /r/stocks/comments/1kanyf3/trump_slams_amazons...   \n",
       "\n",
       "                                                 url subreddit  \\\n",
       "0  https://www.reddit.com/r/stocks/comments/1kapi...    stocks   \n",
       "1  https://www.reddit.com/r/stocks/comments/1kapf...    stocks   \n",
       "2  https://www.reddit.com/r/stocks/comments/1kap4...    stocks   \n",
       "3  https://www.reddit.com/r/stocks/comments/1kaoy...    stocks   \n",
       "4  https://www.reddit.com/r/stocks/comments/1kany...    stocks   \n",
       "\n",
       "     created_datetime  \n",
       "0 2025-04-29 14:37:36  \n",
       "1 2025-04-29 14:34:09  \n",
       "2 2025-04-29 14:20:14  \n",
       "3 2025-04-29 14:13:15  \n",
       "4 2025-04-29 13:29:02  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f55b34",
   "metadata": {},
   "source": [
    "### --------------------- PROVIAMO CON PIU' SUBREDDIT --------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7803ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Ciclo 1...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Post dai subreddit di mercato\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m market:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     df_market = get_new_reddit_posts(sub, \u001b[43mtoken\u001b[49m)\n\u001b[32m     64\u001b[39m     all_market_posts = pd.concat([all_market_posts, df_market], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Post dai subreddit geopolitici\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'token' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Liste di subreddit\n",
    "market = [\"stocks\", \"investment\", \"wallstreetbets\", \"StockMarket\", \"financialindependence\"]\n",
    "geopolitics = [\"geopolitics\", \"politics\", \"worldnews\", \"news\", \"Economics\"]\n",
    "\n",
    "# Inizializza i dataframe e l'insieme per evitare duplicati\n",
    "all_market_posts = pd.DataFrame()\n",
    "all_geo_posts = pd.DataFrame()\n",
    "seen_ids = set()\n",
    "\n",
    "# Funzione generica per scaricare post da un subreddit\n",
    "def get_new_reddit_posts(subreddit, token):\n",
    "\n",
    "    url = f'https://oauth.reddit.com/r/{subreddit}/new?limit=100'\n",
    "    headers = {\n",
    "        'Authorization': f'bearer {token}',\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        posts = data['data']['children']\n",
    "        posts_list = []\n",
    "\n",
    "        for post in posts:\n",
    "            post_data = post['data']\n",
    "            post_id = post_data.get('id')\n",
    "            if post_id not in seen_ids:\n",
    "                seen_ids.add(post_id)\n",
    "                posts_list.append({\n",
    "                    'id': post_id,\n",
    "                    'title': post_data.get('title'),\n",
    "                    'author': post_data.get('author'),\n",
    "                    'text': post_data.get('selftext', ''),\n",
    "                    'score': post_data.get('score'),\n",
    "                    'num_comments': post_data.get('num_comments'),\n",
    "                    'created_utc': post_data.get('created_utc'),\n",
    "                    'permalink': post_data.get('permalink'),\n",
    "                    'url': post_data.get('url'),\n",
    "                    'subreddit': post_data.get('subreddit')\n",
    "                })\n",
    "\n",
    "        df_new = pd.DataFrame(posts_list)\n",
    "        print(f\"[{subreddit}] Post trovati: {len(posts)}\")\n",
    "        if not df_new.empty:\n",
    "            df_new['created_datetime'] = pd.to_datetime(df_new['created_utc'], unit='s')\n",
    "            print(f\"Nuovi aggiunti: {len(df_new)}\")\n",
    "        return df_new\n",
    "    else:\n",
    "        print(f\"[{subreddit}] Errore nella richiesta: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Esegui il polling ogni 30 secondi per N cicli\n",
    "for i in range(6):  # esegue per 3 minuti (6 x 30s)\n",
    "    print(f\"\\nüîÅ Ciclo {i+1}...\")\n",
    "    \n",
    "    # Post dai subreddit di mercato\n",
    "    for sub in market:\n",
    "        df_market = get_new_reddit_posts(sub, token)\n",
    "        all_market_posts = pd.concat([all_market_posts, df_market], ignore_index=True)\n",
    "    \n",
    "    # Post dai subreddit geopolitici\n",
    "    for sub in geopolitics:\n",
    "        df_geo = get_new_reddit_posts(sub, token)\n",
    "        all_geo_posts = pd.concat([all_geo_posts, df_geo], ignore_index=True)\n",
    "\n",
    "    print(\"‚è≥ Pausa 30 secondi...\\n\")\n",
    "    time.sleep(30)\n",
    "\n",
    "# Rimuovi duplicati\n",
    "all_market_posts.drop_duplicates(subset='id', inplace=True)\n",
    "all_geo_posts.drop_duplicates(subset='id', inplace=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Totale post MARKET raccolti: {len(all_market_posts)}\")\n",
    "print(f\"‚úÖ Totale post GEOPOLITICS raccolti: {len(all_geo_posts)}\")\n",
    "\n",
    "# Salvataggio (opzionale)\n",
    "# all_market_posts.to_csv(\"market_posts.csv\", index=False)\n",
    "# all_geo_posts.to_csv(\"geo_posts.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d65c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1kdp0zl</td>\n",
       "      <td>/r/Stocks Weekend Discussion Saturday - May 03...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>This is the weekend edition of our stickied di...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.746265e+09</td>\n",
       "      <td>/r/stocks/comments/1kdp0zl/rstocks_weekend_dis...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdp0...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-05-03 09:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1kdix47</td>\n",
       "      <td>Is it possible that import front-running actua...</td>\n",
       "      <td>beerion</td>\n",
       "      <td>So I've been digging into the mechanics of how...</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>1.746241e+09</td>\n",
       "      <td>/r/stocks/comments/1kdix47/is_it_possible_that...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdix...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-05-03 02:53:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1kdhx8a</td>\n",
       "      <td>Paper Varian medical group stocks issued in th...</td>\n",
       "      <td>ThisIsDogePleaseHodl</td>\n",
       "      <td>Does anyone have any idea how I would go about...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1.746237e+09</td>\n",
       "      <td>/r/stocks/comments/1kdhx8a/paper_varian_medica...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdhx...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-05-03 01:58:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1kdf4ts</td>\n",
       "      <td>Exxon Mobil stock from my grandpa</td>\n",
       "      <td>Camaro_z28</td>\n",
       "      <td>Hey all, recently I met my mother for the firs...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1.746229e+09</td>\n",
       "      <td>/r/stocks/comments/1kdf4ts/exxon_mobil_stock_f...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdf4...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-05-02 23:34:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1kdelb2</td>\n",
       "      <td>S&amp;amp;P logs longest winning streak in 20+ years</td>\n",
       "      <td>llccill</td>\n",
       "      <td>Market relief came from multiple directions to...</td>\n",
       "      <td>183</td>\n",
       "      <td>185</td>\n",
       "      <td>1.746227e+09</td>\n",
       "      <td>/r/stocks/comments/1kdelb2/sp_logs_longest_win...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdel...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-05-02 23:08:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1jlqsz3</td>\n",
       "      <td>Daily FI discussion thread - Friday, March 28,...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Please use this thread to have discussions whi...</td>\n",
       "      <td>36</td>\n",
       "      <td>313</td>\n",
       "      <td>1.743153e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jlqsz3/dail...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>2025-03-28 09:03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1jlenwi</td>\n",
       "      <td>Upcoming layoff is making me rethink financial...</td>\n",
       "      <td>SensibleTexican</td>\n",
       "      <td>In January, I received the news my role and te...</td>\n",
       "      <td>111</td>\n",
       "      <td>97</td>\n",
       "      <td>1.743112e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jlenwi/upco...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>2025-03-27 21:44:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1jl9e6d</td>\n",
       "      <td>Rule of 55 again</td>\n",
       "      <td>Camille_Toh</td>\n",
       "      <td>I've read several threads on the RO55 and have...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>1.743096e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jl9e6d/rule...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>2025-03-27 17:25:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1jkznf0</td>\n",
       "      <td>Daily FI discussion thread - Thursday, March 2...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>Please use this thread to have discussions whi...</td>\n",
       "      <td>26</td>\n",
       "      <td>196</td>\n",
       "      <td>1.743066e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jkznf0/dail...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>2025-03-27 09:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1jkx7lf</td>\n",
       "      <td>[30 F] wanting to quit 60k corporate job for w...</td>\n",
       "      <td>unorthodoxninja</td>\n",
       "      <td>HEY! 7 years ago I came to this subreddit to a...</td>\n",
       "      <td>2540</td>\n",
       "      <td>82</td>\n",
       "      <td>1.743055e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jkx7lf/30_f...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>2025-03-27 05:56:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0    1kdp0zl  /r/Stocks Weekend Discussion Saturday - May 03...   \n",
       "1    1kdix47  Is it possible that import front-running actua...   \n",
       "2    1kdhx8a  Paper Varian medical group stocks issued in th...   \n",
       "3    1kdf4ts                  Exxon Mobil stock from my grandpa   \n",
       "4    1kdelb2   S&amp;P logs longest winning streak in 20+ years   \n",
       "..       ...                                                ...   \n",
       "495  1jlqsz3  Daily FI discussion thread - Friday, March 28,...   \n",
       "496  1jlenwi  Upcoming layoff is making me rethink financial...   \n",
       "497  1jl9e6d                                   Rule of 55 again   \n",
       "498  1jkznf0  Daily FI discussion thread - Thursday, March 2...   \n",
       "499  1jkx7lf  [30 F] wanting to quit 60k corporate job for w...   \n",
       "\n",
       "                   author                                           selftext  \\\n",
       "0           AutoModerator  This is the weekend edition of our stickied di...   \n",
       "1                 beerion  So I've been digging into the mechanics of how...   \n",
       "2    ThisIsDogePleaseHodl  Does anyone have any idea how I would go about...   \n",
       "3              Camaro_z28  Hey all, recently I met my mother for the firs...   \n",
       "4                 llccill  Market relief came from multiple directions to...   \n",
       "..                    ...                                                ...   \n",
       "495         AutoModerator  Please use this thread to have discussions whi...   \n",
       "496       SensibleTexican  In January, I received the news my role and te...   \n",
       "497           Camille_Toh  I've read several threads on the RO55 and have...   \n",
       "498         AutoModerator  Please use this thread to have discussions whi...   \n",
       "499       unorthodoxninja  HEY! 7 years ago I came to this subreddit to a...   \n",
       "\n",
       "     score  num_comments   created_utc  \\\n",
       "0        1             2  1.746265e+09   \n",
       "1       22            14  1.746241e+09   \n",
       "2        6             3  1.746237e+09   \n",
       "3       12             4  1.746229e+09   \n",
       "4      183           185  1.746227e+09   \n",
       "..     ...           ...           ...   \n",
       "495     36           313  1.743153e+09   \n",
       "496    111            97  1.743112e+09   \n",
       "497     23            16  1.743096e+09   \n",
       "498     26           196  1.743066e+09   \n",
       "499   2540            82  1.743055e+09   \n",
       "\n",
       "                                             permalink  \\\n",
       "0    /r/stocks/comments/1kdp0zl/rstocks_weekend_dis...   \n",
       "1    /r/stocks/comments/1kdix47/is_it_possible_that...   \n",
       "2    /r/stocks/comments/1kdhx8a/paper_varian_medica...   \n",
       "3    /r/stocks/comments/1kdf4ts/exxon_mobil_stock_f...   \n",
       "4    /r/stocks/comments/1kdelb2/sp_logs_longest_win...   \n",
       "..                                                 ...   \n",
       "495  /r/financialindependence/comments/1jlqsz3/dail...   \n",
       "496  /r/financialindependence/comments/1jlenwi/upco...   \n",
       "497  /r/financialindependence/comments/1jl9e6d/rule...   \n",
       "498  /r/financialindependence/comments/1jkznf0/dail...   \n",
       "499  /r/financialindependence/comments/1jkx7lf/30_f...   \n",
       "\n",
       "                                                   url              subreddit  \\\n",
       "0    https://www.reddit.com/r/stocks/comments/1kdp0...                 stocks   \n",
       "1    https://www.reddit.com/r/stocks/comments/1kdix...                 stocks   \n",
       "2    https://www.reddit.com/r/stocks/comments/1kdhx...                 stocks   \n",
       "3    https://www.reddit.com/r/stocks/comments/1kdf4...                 stocks   \n",
       "4    https://www.reddit.com/r/stocks/comments/1kdel...                 stocks   \n",
       "..                                                 ...                    ...   \n",
       "495  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "496  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "497  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "498  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "499  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "\n",
       "       created_datetime  \n",
       "0   2025-05-03 09:30:44  \n",
       "1   2025-05-03 02:53:05  \n",
       "2   2025-05-03 01:58:05  \n",
       "3   2025-05-02 23:34:11  \n",
       "4   2025-05-02 23:08:13  \n",
       "..                  ...  \n",
       "495 2025-03-28 09:03:46  \n",
       "496 2025-03-27 21:44:17  \n",
       "497 2025-03-27 17:25:05  \n",
       "498 2025-03-27 09:03:17  \n",
       "499 2025-03-27 05:56:33  \n",
       "\n",
       "[500 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_market_posts.shape)\n",
    "all_market_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf4f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Ciclo 1...\n",
      "[stocks] Post trovati: 100\n",
      "Nuovi aggiunti: 100\n",
      "[investment] Post trovati: 100\n",
      "Nuovi aggiunti: 100\n",
      "[wallstreetbets] Post trovati: 100\n",
      "Nuovi aggiunti: 100\n",
      "[StockMarket] Post trovati: 100\n",
      "Nuovi aggiunti: 100\n",
      "[financialindependence] Post trovati: 100\n",
      "Nuovi aggiunti: 100\n",
      "[geopolitics] Post trovati: 100\n",
      "Nuovi aggiunti: 100\n",
      "[politics] Post trovati: 100\n",
      "Nuovi aggiunti: 100\n",
      "[worldnews] Post trovati: 100\n",
      "Nuovi aggiunti: 100\n",
      "[news] Post trovati: 96\n",
      "Nuovi aggiunti: 96\n",
      "[Economics] Post trovati: 100\n",
      "Nuovi aggiunti: 100\n",
      "‚è≥ Pausa 30 secondi...\n",
      "\n",
      "\n",
      "üîÅ Ciclo 2...\n",
      "[stocks] Post trovati: 100\n",
      "[investment] Post trovati: 100\n",
      "[wallstreetbets] Post trovati: 100\n",
      "[StockMarket] Post trovati: 100\n",
      "[financialindependence] Post trovati: 100\n",
      "[geopolitics] Post trovati: 100\n",
      "[politics] Post trovati: 100\n",
      "Nuovi aggiunti: 1\n",
      "[worldnews] Post trovati: 100\n",
      "[news] Post trovati: 96\n",
      "[Economics] Post trovati: 100\n",
      "‚è≥ Pausa 30 secondi...\n",
      "\n",
      "\n",
      "üîÅ Ciclo 3...\n",
      "[stocks] Post trovati: 100\n",
      "[investment] Post trovati: 100\n",
      "[wallstreetbets] Post trovati: 100\n",
      "[StockMarket] Post trovati: 100\n",
      "[financialindependence] Post trovati: 100\n",
      "[geopolitics] Post trovati: 100\n",
      "[politics] Post trovati: 100\n",
      "Nuovi aggiunti: 1\n",
      "[worldnews] Post trovati: 100\n",
      "[news] Post trovati: 96\n",
      "[Economics] Post trovati: 100\n",
      "‚è≥ Pausa 30 secondi...\n",
      "\n",
      "\n",
      "üîÅ Ciclo 4...\n",
      "[stocks] Post trovati: 100\n",
      "[investment] Post trovati: 100\n",
      "[wallstreetbets] Post trovati: 100\n",
      "[StockMarket] Post trovati: 100\n",
      "[financialindependence] Post trovati: 100\n",
      "[geopolitics] Post trovati: 100\n",
      "[politics] Post trovati: 100\n",
      "[worldnews] Post trovati: 100\n",
      "[news] Post trovati: 96\n",
      "[Economics] Post trovati: 100\n",
      "‚è≥ Pausa 30 secondi...\n",
      "\n",
      "\n",
      "üîÅ Ciclo 5...\n",
      "[stocks] Post trovati: 100\n",
      "[investment] Post trovati: 100\n",
      "[wallstreetbets] Post trovati: 100\n",
      "[StockMarket] Post trovati: 100\n",
      "[financialindependence] Post trovati: 100\n",
      "[geopolitics] Post trovati: 100\n",
      "[politics] Post trovati: 100\n",
      "Nuovi aggiunti: 1\n",
      "[worldnews] Post trovati: 100\n",
      "[news] Post trovati: 96\n",
      "[Economics] Post trovati: 100\n",
      "‚è≥ Pausa 30 secondi...\n",
      "\n",
      "\n",
      "üîÅ Ciclo 6...\n",
      "[stocks] Post trovati: 100\n",
      "[investment] Post trovati: 100\n",
      "[wallstreetbets] Post trovati: 100\n",
      "[StockMarket] Post trovati: 100\n",
      "[financialindependence] Post trovati: 100\n",
      "[geopolitics] Post trovati: 100\n",
      "[politics] Post trovati: 100\n",
      "[worldnews] Post trovati: 100\n",
      "[news] Post trovati: 96\n",
      "[Economics] Post trovati: 100\n",
      "‚è≥ Pausa 30 secondi...\n",
      "\n",
      "\n",
      "‚úÖ Totale post MARKET raccolti: 500\n",
      "‚úÖ Totale post GEOPOLITICS raccolti: 499\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Liste di subreddit\n",
    "market = [\"stocks\", \"investment\", \"wallstreetbets\", \"StockMarket\", \"financialindependence\"]\n",
    "geopolitics = [\"geopolitics\", \"politics\", \"worldnews\", \"news\", \"Economics\"]\n",
    "\n",
    "# Inizializza i dataframe e l'insieme per evitare duplicati\n",
    "all_market_posts = pd.DataFrame()\n",
    "all_geo_posts = pd.DataFrame()\n",
    "seen_ids = set()\n",
    "\n",
    "# Funzione per scaricare i commenti di un post\n",
    "def get_comments(post_id):\n",
    "    url = f'https://oauth.reddit.com/comments/{post_id}?limit=100'\n",
    "    headers = {\n",
    "        'Authorization': f'bearer {token}',\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        comments_data = response.json()[1]['data']['children']\n",
    "        comments_list = []\n",
    "        for comment in comments_data:\n",
    "            comment_data = comment['data']\n",
    "            comments_list.append({\n",
    "                'comment_id': comment_data.get('id'),\n",
    "                'author': comment_data.get('author'),\n",
    "                'score': comment_data.get('score'),\n",
    "                'body': comment_data.get('body'),\n",
    "                'created_utc': comment_data.get('created_utc'),\n",
    "                'post_id': post_id\n",
    "            })\n",
    "        return pd.DataFrame(comments_list)\n",
    "    else:\n",
    "        print(f\"Errore nel recuperare i commenti per il post {post_id}: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Funzione per scaricare post da un subreddit e i loro commenti\n",
    "def get_new_reddit_posts(subreddit, token):\n",
    "\n",
    "    url = f'https://oauth.reddit.com/r/{subreddit}/new?limit=10'\n",
    "    headers = {\n",
    "        'Authorization': f'bearer {token}',\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        posts = data['data']['children']\n",
    "        posts_list = []\n",
    "\n",
    "        for post in posts:\n",
    "            post_data = post['data']\n",
    "            post_id = post_data.get('id')\n",
    "            if post_id not in seen_ids:\n",
    "                seen_ids.add(post_id)\n",
    "                # Recupera anche i commenti per ogni post\n",
    "                comments_df = get_comments(post_id)\n",
    "                \n",
    "                # Aggiungi i post e i commenti a un unico dataframe\n",
    "                posts_list.append({\n",
    "                    'id': post_id,\n",
    "                    'title': post_data.get('title'),\n",
    "                    'text': post_data.get('selftext', ''),\n",
    "                    'author': post_data.get('author'),\n",
    "                    'score': post_data.get('score'),\n",
    "                    'num_comments': post_data.get('num_comments'),\n",
    "                    'created_utc': post_data.get('created_utc'),\n",
    "                    'permalink': post_data.get('permalink'),\n",
    "                    'url': post_data.get('url'),\n",
    "                    'subreddit': post_data.get('subreddit'),\n",
    "                    'comments': comments_df  # Aggiungi il dataframe dei commenti\n",
    "                })\n",
    "                \n",
    "        df_new = pd.DataFrame(posts_list)\n",
    "        print(f\"[{subreddit}] Post trovati: {len(posts)}\")\n",
    "        if not df_new.empty:\n",
    "            df_new['created_datetime'] = pd.to_datetime(df_new['created_utc'], unit='s')\n",
    "            print(f\"Nuovi aggiunti: {len(df_new)}\")\n",
    "        return df_new\n",
    "    else:\n",
    "        print(f\"[{subreddit}] Errore nella richiesta: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Esegui il polling ogni 30 secondi per N cicli\n",
    "for i in range(6):  # esegue per 3 minuti (6 x 30s)\n",
    "    print(f\"\\nüîÅ Ciclo {i+1}...\")\n",
    "    \n",
    "    # Post dai subreddit di mercato\n",
    "    for sub in market:\n",
    "        df_market = get_new_reddit_posts(sub, token)\n",
    "        all_market_posts = pd.concat([all_market_posts, df_market], ignore_index=True)\n",
    "    \n",
    "    # Post dai subreddit geopolitici\n",
    "    for sub in geopolitics:\n",
    "        df_geo = get_new_reddit_posts(sub, token)\n",
    "        all_geo_posts = pd.concat([all_geo_posts, df_geo], ignore_index=True)\n",
    "\n",
    "    print(\"‚è≥ Pausa 30 secondi...\\n\")\n",
    "    time.sleep(30)\n",
    "\n",
    "# Rimuovi duplicati\n",
    "all_market_posts.drop_duplicates(subset='id', inplace=True)\n",
    "all_geo_posts.drop_duplicates(subset='id', inplace=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Totale post MARKET raccolti: {len(all_market_posts)}\")\n",
    "print(f\"‚úÖ Totale post GEOPOLITICS raccolti: {len(all_geo_posts)}\")\n",
    "\n",
    "# Salvataggio (opzionale)\n",
    "# all_market_posts.to_csv(\"market_posts.csv\", index=False)\n",
    "# all_geo_posts.to_csv(\"geo_posts.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033fdbaa",
   "metadata": {},
   "source": [
    "Il comando √® molto lento, ma non √® ancora parallellizato e inoltre √® lento perch√® al primo ciclo ne cerca 100, poi, ogni 30 secondi rilancia il codice ma trova tipo solo 1 nuovo post, quindi ci mette molto poco a trovare anche i commenti. continuativamente non dovrebbe essere un problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8044e1",
   "metadata": {},
   "source": [
    "Problema: se prendiamo i post in live, sotto non avranno neanche un commento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f63b0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1kdpocm</td>\n",
       "      <td>Google Antitrust</td>\n",
       "      <td>I have seen only minimal talks in the sub abou...</td>\n",
       "      <td>TorpCat</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1.746267e+09</td>\n",
       "      <td>/r/stocks/comments/1kdpocm/google_antitrust/</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdpo...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>comment_id   author  score  \\\n",
       "0    mqck7h7  ...</td>\n",
       "      <td>2025-05-03 10:16:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1kdp0zl</td>\n",
       "      <td>/r/Stocks Weekend Discussion Saturday - May 03...</td>\n",
       "      <td>This is the weekend edition of our stickied di...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.746265e+09</td>\n",
       "      <td>/r/stocks/comments/1kdp0zl/rstocks_weekend_dis...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdp0...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>comment_id               author  score  \\\n",
       "0 ...</td>\n",
       "      <td>2025-05-03 09:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1kdix47</td>\n",
       "      <td>Is it possible that import front-running actua...</td>\n",
       "      <td>So I've been digging into the mechanics of how...</td>\n",
       "      <td>beerion</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>1.746241e+09</td>\n",
       "      <td>/r/stocks/comments/1kdix47/is_it_possible_that...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdix...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>comment_id                author  score  \\\n",
       "0...</td>\n",
       "      <td>2025-05-03 02:53:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1kdhx8a</td>\n",
       "      <td>Paper Varian medical group stocks issued in th...</td>\n",
       "      <td>Does anyone have any idea how I would go about...</td>\n",
       "      <td>ThisIsDogePleaseHodl</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.746237e+09</td>\n",
       "      <td>/r/stocks/comments/1kdhx8a/paper_varian_medica...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdhx...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>comment_id               author  score  \\\n",
       "0 ...</td>\n",
       "      <td>2025-05-03 01:58:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1kdf4ts</td>\n",
       "      <td>Exxon Mobil stock from my grandpa</td>\n",
       "      <td>Hey all, recently I met my mother for the firs...</td>\n",
       "      <td>Camaro_z28</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1.746229e+09</td>\n",
       "      <td>/r/stocks/comments/1kdf4ts/exxon_mobil_stock_f...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kdf4...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>comment_id               author  score  \\\n",
       "0 ...</td>\n",
       "      <td>2025-05-02 23:34:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1jlqsz3</td>\n",
       "      <td>Daily FI discussion thread - Friday, March 28,...</td>\n",
       "      <td>Please use this thread to have discussions whi...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>39</td>\n",
       "      <td>313</td>\n",
       "      <td>1.743153e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jlqsz3/dail...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>comment_id            author  score  \\\n",
       "0   ...</td>\n",
       "      <td>2025-03-28 09:03:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1jlenwi</td>\n",
       "      <td>Upcoming layoff is making me rethink financial...</td>\n",
       "      <td>In January, I received the news my role and te...</td>\n",
       "      <td>SensibleTexican</td>\n",
       "      <td>110</td>\n",
       "      <td>97</td>\n",
       "      <td>1.743112e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jlenwi/upco...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>comment_id               author  score  \\\n",
       "0...</td>\n",
       "      <td>2025-03-27 21:44:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1jl9e6d</td>\n",
       "      <td>Rule of 55 again</td>\n",
       "      <td>I've read several threads on the RO55 and have...</td>\n",
       "      <td>Camille_Toh</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>1.743096e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jl9e6d/rule...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>comment_id             author  score  \\\n",
       "0   ...</td>\n",
       "      <td>2025-03-27 17:25:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1jkznf0</td>\n",
       "      <td>Daily FI discussion thread - Thursday, March 2...</td>\n",
       "      <td>Please use this thread to have discussions whi...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>27</td>\n",
       "      <td>196</td>\n",
       "      <td>1.743066e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jkznf0/dail...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>comment_id                author  score  \\\n",
       "...</td>\n",
       "      <td>2025-03-27 09:03:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1jkx7lf</td>\n",
       "      <td>[30 F] wanting to quit 60k corporate job for w...</td>\n",
       "      <td>HEY! 7 years ago I came to this subreddit to a...</td>\n",
       "      <td>unorthodoxninja</td>\n",
       "      <td>2530</td>\n",
       "      <td>82</td>\n",
       "      <td>1.743055e+09</td>\n",
       "      <td>/r/financialindependence/comments/1jkx7lf/30_f...</td>\n",
       "      <td>https://www.reddit.com/r/financialindependence...</td>\n",
       "      <td>financialindependence</td>\n",
       "      <td>comment_id                author  score  \\\n",
       "...</td>\n",
       "      <td>2025-03-27 05:56:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0    1kdpocm                                   Google Antitrust   \n",
       "1    1kdp0zl  /r/Stocks Weekend Discussion Saturday - May 03...   \n",
       "2    1kdix47  Is it possible that import front-running actua...   \n",
       "3    1kdhx8a  Paper Varian medical group stocks issued in th...   \n",
       "4    1kdf4ts                  Exxon Mobil stock from my grandpa   \n",
       "..       ...                                                ...   \n",
       "495  1jlqsz3  Daily FI discussion thread - Friday, March 28,...   \n",
       "496  1jlenwi  Upcoming layoff is making me rethink financial...   \n",
       "497  1jl9e6d                                   Rule of 55 again   \n",
       "498  1jkznf0  Daily FI discussion thread - Thursday, March 2...   \n",
       "499  1jkx7lf  [30 F] wanting to quit 60k corporate job for w...   \n",
       "\n",
       "                                                  text                author  \\\n",
       "0    I have seen only minimal talks in the sub abou...               TorpCat   \n",
       "1    This is the weekend edition of our stickied di...         AutoModerator   \n",
       "2    So I've been digging into the mechanics of how...               beerion   \n",
       "3    Does anyone have any idea how I would go about...  ThisIsDogePleaseHodl   \n",
       "4    Hey all, recently I met my mother for the firs...            Camaro_z28   \n",
       "..                                                 ...                   ...   \n",
       "495  Please use this thread to have discussions whi...         AutoModerator   \n",
       "496  In January, I received the news my role and te...       SensibleTexican   \n",
       "497  I've read several threads on the RO55 and have...           Camille_Toh   \n",
       "498  Please use this thread to have discussions whi...         AutoModerator   \n",
       "499  HEY! 7 years ago I came to this subreddit to a...       unorthodoxninja   \n",
       "\n",
       "     score  num_comments   created_utc  \\\n",
       "0       11             2  1.746267e+09   \n",
       "1        4             3  1.746265e+09   \n",
       "2       24            16  1.746241e+09   \n",
       "3        4             3  1.746237e+09   \n",
       "4       12             4  1.746229e+09   \n",
       "..     ...           ...           ...   \n",
       "495     39           313  1.743153e+09   \n",
       "496    110            97  1.743112e+09   \n",
       "497     24            16  1.743096e+09   \n",
       "498     27           196  1.743066e+09   \n",
       "499   2530            82  1.743055e+09   \n",
       "\n",
       "                                             permalink  \\\n",
       "0         /r/stocks/comments/1kdpocm/google_antitrust/   \n",
       "1    /r/stocks/comments/1kdp0zl/rstocks_weekend_dis...   \n",
       "2    /r/stocks/comments/1kdix47/is_it_possible_that...   \n",
       "3    /r/stocks/comments/1kdhx8a/paper_varian_medica...   \n",
       "4    /r/stocks/comments/1kdf4ts/exxon_mobil_stock_f...   \n",
       "..                                                 ...   \n",
       "495  /r/financialindependence/comments/1jlqsz3/dail...   \n",
       "496  /r/financialindependence/comments/1jlenwi/upco...   \n",
       "497  /r/financialindependence/comments/1jl9e6d/rule...   \n",
       "498  /r/financialindependence/comments/1jkznf0/dail...   \n",
       "499  /r/financialindependence/comments/1jkx7lf/30_f...   \n",
       "\n",
       "                                                   url              subreddit  \\\n",
       "0    https://www.reddit.com/r/stocks/comments/1kdpo...                 stocks   \n",
       "1    https://www.reddit.com/r/stocks/comments/1kdp0...                 stocks   \n",
       "2    https://www.reddit.com/r/stocks/comments/1kdix...                 stocks   \n",
       "3    https://www.reddit.com/r/stocks/comments/1kdhx...                 stocks   \n",
       "4    https://www.reddit.com/r/stocks/comments/1kdf4...                 stocks   \n",
       "..                                                 ...                    ...   \n",
       "495  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "496  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "497  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "498  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "499  https://www.reddit.com/r/financialindependence...  financialindependence   \n",
       "\n",
       "                                              comments    created_datetime  \n",
       "0      comment_id   author  score  \\\n",
       "0    mqck7h7  ... 2025-05-03 10:16:32  \n",
       "1      comment_id               author  score  \\\n",
       "0 ... 2025-05-03 09:30:44  \n",
       "2      comment_id                author  score  \\\n",
       "0... 2025-05-03 02:53:05  \n",
       "3      comment_id               author  score  \\\n",
       "0 ... 2025-05-03 01:58:05  \n",
       "4      comment_id               author  score  \\\n",
       "0 ... 2025-05-02 23:34:11  \n",
       "..                                                 ...                 ...  \n",
       "495     comment_id            author  score  \\\n",
       "0   ... 2025-03-28 09:03:46  \n",
       "496     comment_id               author  score  \\\n",
       "0... 2025-03-27 21:44:17  \n",
       "497    comment_id             author  score  \\\n",
       "0   ... 2025-03-27 17:25:05  \n",
       "498     comment_id                author  score  \\\n",
       "... 2025-03-27 09:03:17  \n",
       "499     comment_id                author  score  \\\n",
       "... 2025-03-27 05:56:33  \n",
       "\n",
       "[500 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_market_posts.shape)\n",
    "all_market_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e63f476",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_market_posts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mall_market_posts\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mcomments\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'all_market_posts' is not defined"
     ]
    }
   ],
   "source": [
    "all_market_posts[\"comments\"][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data-finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
