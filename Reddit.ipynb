{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44936b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Configura le tue credenziali Reddit\n",
    "client_id = 'XpeJWmueFBEGkyXjE-dpcA'\n",
    "client_secret = 'yOyCLHaB0Ur7R0sW75UUmc20MjCPkw'\n",
    "user_agent = 'Samu_Miki'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per ottenere un token\n",
    "def get_reddit_token(client_id, client_secret, user_agent):\n",
    "    url = 'https://www.reddit.com/api/v1/access_token'\n",
    "    headers = {\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials'\n",
    "    }\n",
    "    auth = (client_id, client_secret)\n",
    "    \n",
    "    # Fai la richiesta per ottenere il token\n",
    "    response = requests.post(url, headers=headers, data=data, auth=auth)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        token = response.json()['access_token']\n",
    "        print(f'Token ottenuto con successo: {token}')\n",
    "        return token\n",
    "    else:\n",
    "        print(f'Errore durante l\\'ottenimento del token: {response.status_code}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea9d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per fare una richiesta all'API Reddit\n",
    "def get_reddit_posts(token):\n",
    "    url = 'https://oauth.reddit.com/r/stocks/top?t=week&limit=100'\n",
    "    headers = {\n",
    "        'Authorization': f'bearer {token}',\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "    \n",
    "    # Fai la richiesta per ottenere i post    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Estrai i post\n",
    "        posts = data['data']['children']\n",
    "        \n",
    "        # Crea una lista di dizionari con le informazioni che ti interessano\n",
    "        posts_list = []\n",
    "        for post in posts:\n",
    "            post_data = post['data']\n",
    "            posts_list.append({\n",
    "                'id': post_data.get('id'),\n",
    "                'title': post_data.get('title'),\n",
    "                'author': post_data.get('author'),\n",
    "                'score': post_data.get('score'),\n",
    "                'num_comments': post_data.get('num_comments'),\n",
    "                'created_utc': post_data.get('created_utc'),\n",
    "                'permalink': post_data.get('permalink'),\n",
    "                'url': post_data.get('url'),\n",
    "                'subreddit': post_data.get('subreddit')\n",
    "            })\n",
    "\n",
    "        # Crea il DataFrame\n",
    "        df_reddit = pd.DataFrame(posts_list)\n",
    "        df_reddit['created_datetime'] = pd.to_datetime(df_reddit['created_utc'], unit='s')\n",
    "        \n",
    "        print(f'Recuperati {len(df_reddit)} post.')\n",
    "        return df_reddit\n",
    "    \n",
    "    else:\n",
    "        print(f'Errore durante la richiesta ai post: {response.status_code}')\n",
    "        return pd.DataFrame()  # ritorna un df vuoto in caso di errore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837e953d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ottenuto con successo: eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJsb2lkIiwiZXhwIjoxNzQ2MDIzNTc2LjUxMDA3LCJpYXQiOjE3NDU5MzcxNzYuNTEwMDcsImp0aSI6IlJTQTZ4TVhZQ283TVJsWEs0ZUhlZHRsRkh4ODhUZyIsImNpZCI6IlhwZUpXbXVlRkJFR2t5WGpFLWRwY0EiLCJsaWQiOiJ0Ml8xb2J2cnQ4eWRrIiwibGNhIjoxNzQ1OTM3MTc2NDkzLCJzY3AiOiJlSnlLVnRKU2lnVUVBQURfX3dOekFTYyIsImZsbyI6Nn0.slQiLoYyqEyzg9H2UQWJWZQ7pAWjhT-by_gjW2vgiVho0no2eYaTTQbBmEDupLKGU5R5ySMSsVDPMrX8X9jhe6Qq4F6q_-LzuBkgID0JBILGlxvpKp2FL2l78R62JQYUDKNmNtsi_G9uZUqYr30TyABg6z4pAiTBcGBHPPSZMWQrBvuClWShdL3a6itHgUQkH36ShTXT97A7n3BISGH1dEW5bSYWea692F8QEpZkMTj9i15ikaRa4BHC8swZaoHj7lD8B0GhYTU5W3KkOw2E17lBwpOI3zp3NIglumJYfQXqrujBv4uZQAJIO6UoBTMS4tvpqcS_xLaRuTrK0z6a_g\n"
     ]
    }
   ],
   "source": [
    "#ottenere il token:\n",
    "token = get_reddit_token(client_id, client_secret, user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e4f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PER ORA NON USARE, SERVE PER AVERNE UNO AL GIORNO, PER INTANTO LO FACCIAMO MANUALMENTE CON I COMANDI SOPRA\n",
    "\n",
    "# Ciclo per ottenere e usare il token ogni giorno\n",
    "while True:\n",
    "    # Ottieni il token (scade dopo 24 ore)\n",
    "    token = get_reddit_token(client_id, client_secret, user_agent)\n",
    "    \n",
    "    if token:\n",
    "        # Usa il token per fare la richiesta all'API\n",
    "        get_reddit_posts(token)\n",
    "    \n",
    "    # Aspetta 24 ore (86400 secondi) prima di ottenere un nuovo token\n",
    "    print('Aspetta 24 ore per ottenere un nuovo token...')\n",
    "    time.sleep(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d22b1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recuperati 100 post.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1k6pihz</td>\n",
       "      <td>Now we know. It was Retail CEOS who got to Tru...</td>\n",
       "      <td>Epicurus-fan</td>\n",
       "      <td>47508</td>\n",
       "      <td>2930</td>\n",
       "      <td>1.745493e+09</td>\n",
       "      <td>/r/stocks/comments/1k6pihz/now_we_know_it_was_...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k6pi...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-24 11:09:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1k75t88</td>\n",
       "      <td>Fox Reporter Says the Trump White House Is Giv...</td>\n",
       "      <td>GaussInTheHouse</td>\n",
       "      <td>45042</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.745535e+09</td>\n",
       "      <td>/r/stocks/comments/1k75t88/fox_reporter_says_t...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k75t...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-24 22:51:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1kadl0p</td>\n",
       "      <td>China Officially Makes Statement Stating That ...</td>\n",
       "      <td>Onnimation</td>\n",
       "      <td>34149</td>\n",
       "      <td>2535</td>\n",
       "      <td>1.745894e+09</td>\n",
       "      <td>/r/stocks/comments/1kadl0p/china_officially_ma...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kadl...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 02:40:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1k5g9yj</td>\n",
       "      <td>Tesla reports disappointing quarterly results ...</td>\n",
       "      <td>Puginator</td>\n",
       "      <td>13938</td>\n",
       "      <td>985</td>\n",
       "      <td>1.745353e+09</td>\n",
       "      <td>/r/stocks/comments/1k5g9yj/tesla_reports_disap...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k5g9...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-22 20:13:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1k9vrt4</td>\n",
       "      <td>Agriculture isn't nearing trade war tariffs cr...</td>\n",
       "      <td>AssociateGreat2350</td>\n",
       "      <td>10086</td>\n",
       "      <td>923</td>\n",
       "      <td>1.745848e+09</td>\n",
       "      <td>/r/stocks/comments/1k9vrt4/agriculture_isnt_ne...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k9vr...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-28 13:39:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1k8t08k</td>\n",
       "      <td>Which of these is not like the others?</td>\n",
       "      <td>30030s</td>\n",
       "      <td>118</td>\n",
       "      <td>59</td>\n",
       "      <td>1.745719e+09</td>\n",
       "      <td>/r/stocks/comments/1k8t08k/which_of_these_is_n...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k8t0...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-27 01:55:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1k9yuu7</td>\n",
       "      <td>China’s Huawei Develops New AI Chip, Seeking t...</td>\n",
       "      <td>SPXQuantAlgo</td>\n",
       "      <td>111</td>\n",
       "      <td>72</td>\n",
       "      <td>1.745855e+09</td>\n",
       "      <td>/r/stocks/comments/1k9yuu7/chinas_huawei_devel...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k9yu...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-28 15:49:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1k94qpa</td>\n",
       "      <td>Is anyone else looking at Goodyear stock?</td>\n",
       "      <td>Cloudbb333</td>\n",
       "      <td>88</td>\n",
       "      <td>62</td>\n",
       "      <td>1.745763e+09</td>\n",
       "      <td>/r/stocks/comments/1k94qpa/is_anyone_else_look...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k94q...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-27 14:05:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1k7yuoj</td>\n",
       "      <td>So how does the lowered regulation for autonom...</td>\n",
       "      <td>zitrored</td>\n",
       "      <td>86</td>\n",
       "      <td>60</td>\n",
       "      <td>1.745623e+09</td>\n",
       "      <td>/r/stocks/comments/1k7yuoj/so_how_does_the_low...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1k7yu...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-25 23:20:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1ka8l67</td>\n",
       "      <td>Stock market today: Dow, S&amp;amp;P 500 erase sli...</td>\n",
       "      <td>Amehoelazeg</td>\n",
       "      <td>77</td>\n",
       "      <td>13</td>\n",
       "      <td>1.745880e+09</td>\n",
       "      <td>/r/stocks/comments/1ka8l67/stock_market_today_...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1ka8l...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-28 22:32:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0   1k6pihz  Now we know. It was Retail CEOS who got to Tru...   \n",
       "1   1k75t88  Fox Reporter Says the Trump White House Is Giv...   \n",
       "2   1kadl0p  China Officially Makes Statement Stating That ...   \n",
       "3   1k5g9yj  Tesla reports disappointing quarterly results ...   \n",
       "4   1k9vrt4  Agriculture isn't nearing trade war tariffs cr...   \n",
       "..      ...                                                ...   \n",
       "95  1k8t08k             Which of these is not like the others?   \n",
       "96  1k9yuu7  China’s Huawei Develops New AI Chip, Seeking t...   \n",
       "97  1k94qpa          Is anyone else looking at Goodyear stock?   \n",
       "98  1k7yuoj  So how does the lowered regulation for autonom...   \n",
       "99  1ka8l67  Stock market today: Dow, S&amp;P 500 erase sli...   \n",
       "\n",
       "                author  score  num_comments   created_utc  \\\n",
       "0         Epicurus-fan  47508          2930  1.745493e+09   \n",
       "1      GaussInTheHouse  45042          1062  1.745535e+09   \n",
       "2           Onnimation  34149          2535  1.745894e+09   \n",
       "3            Puginator  13938           985  1.745353e+09   \n",
       "4   AssociateGreat2350  10086           923  1.745848e+09   \n",
       "..                 ...    ...           ...           ...   \n",
       "95              30030s    118            59  1.745719e+09   \n",
       "96        SPXQuantAlgo    111            72  1.745855e+09   \n",
       "97          Cloudbb333     88            62  1.745763e+09   \n",
       "98            zitrored     86            60  1.745623e+09   \n",
       "99         Amehoelazeg     77            13  1.745880e+09   \n",
       "\n",
       "                                            permalink  \\\n",
       "0   /r/stocks/comments/1k6pihz/now_we_know_it_was_...   \n",
       "1   /r/stocks/comments/1k75t88/fox_reporter_says_t...   \n",
       "2   /r/stocks/comments/1kadl0p/china_officially_ma...   \n",
       "3   /r/stocks/comments/1k5g9yj/tesla_reports_disap...   \n",
       "4   /r/stocks/comments/1k9vrt4/agriculture_isnt_ne...   \n",
       "..                                                ...   \n",
       "95  /r/stocks/comments/1k8t08k/which_of_these_is_n...   \n",
       "96  /r/stocks/comments/1k9yuu7/chinas_huawei_devel...   \n",
       "97  /r/stocks/comments/1k94qpa/is_anyone_else_look...   \n",
       "98  /r/stocks/comments/1k7yuoj/so_how_does_the_low...   \n",
       "99  /r/stocks/comments/1ka8l67/stock_market_today_...   \n",
       "\n",
       "                                                  url subreddit  \\\n",
       "0   https://www.reddit.com/r/stocks/comments/1k6pi...    stocks   \n",
       "1   https://www.reddit.com/r/stocks/comments/1k75t...    stocks   \n",
       "2   https://www.reddit.com/r/stocks/comments/1kadl...    stocks   \n",
       "3   https://www.reddit.com/r/stocks/comments/1k5g9...    stocks   \n",
       "4   https://www.reddit.com/r/stocks/comments/1k9vr...    stocks   \n",
       "..                                                ...       ...   \n",
       "95  https://www.reddit.com/r/stocks/comments/1k8t0...    stocks   \n",
       "96  https://www.reddit.com/r/stocks/comments/1k9yu...    stocks   \n",
       "97  https://www.reddit.com/r/stocks/comments/1k94q...    stocks   \n",
       "98  https://www.reddit.com/r/stocks/comments/1k7yu...    stocks   \n",
       "99  https://www.reddit.com/r/stocks/comments/1ka8l...    stocks   \n",
       "\n",
       "      created_datetime  \n",
       "0  2025-04-24 11:09:27  \n",
       "1  2025-04-24 22:51:38  \n",
       "2  2025-04-29 02:40:04  \n",
       "3  2025-04-22 20:13:09  \n",
       "4  2025-04-28 13:39:05  \n",
       "..                 ...  \n",
       "95 2025-04-27 01:55:47  \n",
       "96 2025-04-28 15:49:50  \n",
       "97 2025-04-27 14:05:59  \n",
       "98 2025-04-25 23:20:31  \n",
       "99 2025-04-28 22:32:06  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reddit_posts(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f797355",
   "metadata": {},
   "source": [
    "Il parametro \"top\" ci permette di usare un parametro temporale, ma ne ranna davvero pochi (es: se metto hour me ne dà 2), forse conviene usare il parametro \"new\" e continuare a runnarlo ogni tot, e semmai fare uno script per sistemare. es: prende i dati ogni 10 secondi, e ne prende 100, se 10 secondi dopo rirunniamo e 20 post sono uguali, lui si accorge che sono uguali e tiene solo gli altri 80, lo stesso si può fare per l'API di finnhub news che mi dà le news solo giornalmente, per non doverlo runnare solo una volta al giorno. Usando \"After\" si possono prendere veramente molti dati, perchè prende la pagina successiva. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41da017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggiunti 100 nuovi post.\n",
      "Nessun nuovo post trovato.\n",
      "Nessun nuovo post trovato.\n",
      "Nessun nuovo post trovato.\n",
      "Nessun nuovo post trovato.\n",
      "Nessun nuovo post trovato.\n",
      "Totale post raccolti: 100\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "all_posts = pd.DataFrame()\n",
    "seen_ids = set()\n",
    "\n",
    "def get_new_reddit_posts(token):\n",
    "    url = 'https://oauth.reddit.com/r/stocks/new?limit=100'\n",
    "    headers = {\n",
    "        'Authorization': f'bearer {token}',\n",
    "        'User-Agent': user_agent\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        posts = data['data']['children']\n",
    "        posts_list = []\n",
    "\n",
    "        for post in posts:\n",
    "            post_data = post['data']\n",
    "            if post_data.get('id') not in seen_ids:\n",
    "                seen_ids.add(post_data.get('id'))\n",
    "                posts_list.append({\n",
    "                    'id': post_data.get('id'),\n",
    "                    'title': post_data.get('title'),\n",
    "                    'author': post_data.get('author'),\n",
    "                    'score': post_data.get('score'),\n",
    "                    'num_comments': post_data.get('num_comments'),                \n",
    "                    'created_utc': post_data.get('created_utc'),\n",
    "                    'permalink': post_data.get('permalink'),\n",
    "                    'url': post_data.get('url'),\n",
    "                    'subreddit': post_data.get('subreddit')\n",
    "                })\n",
    "\n",
    "        df_new = pd.DataFrame(posts_list)\n",
    "        if not df_new.empty:\n",
    "            df_new['created_datetime'] = pd.to_datetime(df_new['created_utc'], unit='s')\n",
    "            print(f'Aggiunti {len(df_new)} nuovi post.')\n",
    "        else:\n",
    "            print('Nessun nuovo post trovato.')\n",
    "\n",
    "        return df_new\n",
    "    else:\n",
    "        print(f'Errore nella richiesta: {response.status_code}')\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Esegui il polling ogni 30 secondi\n",
    "for i in range(6):  # ad esempio per 10 minuti\n",
    "    df = get_new_reddit_posts(token)\n",
    "    all_posts = pd.concat([all_posts, df], ignore_index=True)\n",
    "    time.sleep(30)\n",
    "\n",
    "# Salva alla fine o elabora\n",
    "all_posts.drop_duplicates(subset='id', inplace=True)\n",
    "print(f'Totale post raccolti: {len(all_posts)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c61077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>permalink</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1kapihd</td>\n",
       "      <td>The White House confirmed plans for the Trump ...</td>\n",
       "      <td>lionpenguin88</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>1.745937e+09</td>\n",
       "      <td>/r/stocks/comments/1kapihd/the_white_house_con...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kapi...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 14:37:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1kapflz</td>\n",
       "      <td>Buy/sell types and execution during pre, exten...</td>\n",
       "      <td>4G0T2FLU5H</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.745937e+09</td>\n",
       "      <td>/r/stocks/comments/1kapflz/buysell_types_and_e...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kapf...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 14:34:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1kap42w</td>\n",
       "      <td>UPS to cut 20,000 jobs on lower Amazon shipmen...</td>\n",
       "      <td>joe4942</td>\n",
       "      <td>94</td>\n",
       "      <td>20</td>\n",
       "      <td>1.745936e+09</td>\n",
       "      <td>/r/stocks/comments/1kap42w/ups_to_cut_20000_jo...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kap4...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 14:20:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1kaoyc1</td>\n",
       "      <td>Barrons: Why Trump’s Next 100 Days Will Be Mor...</td>\n",
       "      <td>WantedtoRetireEarly</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>1.745936e+09</td>\n",
       "      <td>/r/stocks/comments/1kaoyc1/barrons_why_trumps_...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kaoy...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 14:13:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1kanyf3</td>\n",
       "      <td>Trump Slams Amazon's Tariff Labeling as ‘Hosti...</td>\n",
       "      <td>eteplirsen</td>\n",
       "      <td>8106</td>\n",
       "      <td>849</td>\n",
       "      <td>1.745933e+09</td>\n",
       "      <td>/r/stocks/comments/1kanyf3/trump_slams_amazons...</td>\n",
       "      <td>https://www.reddit.com/r/stocks/comments/1kany...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>2025-04-29 13:29:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  1kapihd  The White House confirmed plans for the Trump ...   \n",
       "1  1kapflz  Buy/sell types and execution during pre, exten...   \n",
       "2  1kap42w  UPS to cut 20,000 jobs on lower Amazon shipmen...   \n",
       "3  1kaoyc1  Barrons: Why Trump’s Next 100 Days Will Be Mor...   \n",
       "4  1kanyf3  Trump Slams Amazon's Tariff Labeling as ‘Hosti...   \n",
       "\n",
       "                author  score  num_comments   created_utc  \\\n",
       "0        lionpenguin88     33            15  1.745937e+09   \n",
       "1           4G0T2FLU5H      3             0  1.745937e+09   \n",
       "2              joe4942     94            20  1.745936e+09   \n",
       "3  WantedtoRetireEarly     19            13  1.745936e+09   \n",
       "4           eteplirsen   8106           849  1.745933e+09   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/stocks/comments/1kapihd/the_white_house_con...   \n",
       "1  /r/stocks/comments/1kapflz/buysell_types_and_e...   \n",
       "2  /r/stocks/comments/1kap42w/ups_to_cut_20000_jo...   \n",
       "3  /r/stocks/comments/1kaoyc1/barrons_why_trumps_...   \n",
       "4  /r/stocks/comments/1kanyf3/trump_slams_amazons...   \n",
       "\n",
       "                                                 url subreddit  \\\n",
       "0  https://www.reddit.com/r/stocks/comments/1kapi...    stocks   \n",
       "1  https://www.reddit.com/r/stocks/comments/1kapf...    stocks   \n",
       "2  https://www.reddit.com/r/stocks/comments/1kap4...    stocks   \n",
       "3  https://www.reddit.com/r/stocks/comments/1kaoy...    stocks   \n",
       "4  https://www.reddit.com/r/stocks/comments/1kany...    stocks   \n",
       "\n",
       "     created_datetime  \n",
       "0 2025-04-29 14:37:36  \n",
       "1 2025-04-29 14:34:09  \n",
       "2 2025-04-29 14:20:14  \n",
       "3 2025-04-29 14:13:15  \n",
       "4 2025-04-29 13:29:02  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_posts.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-data-finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
