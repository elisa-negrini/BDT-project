PROJECT TOPIC: Stock Market Trend Analysis and Portfolio Insights
Design and prototype a big data system that streams live market data (quotes, volumes, financial news)
and historical stock records into a centralized platform. Leverage natural language processing to gauge
sentiment from financial news and social media. Use Spark or Flink to run real-time anomaly detection
on sudden price fluctuations and predict short-term market trends. Provide portfolio management
insights, highlighting high-risk assets, diversification opportunities, and personalized investment
strategies.

------------------------------------- to be deleted ---------------------------------------------------------
token elisa: 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

SUGGESTED TIMELINE

Following requests from last year, we are proposing a template of a timeline for successfully
delivering your project work. Just take it as a suggestion, and customize it to your specific needs
and schedule.

● Data Exploration & Design (Weeks 1-2)

    ○ Identify and acquire real or synthetic data (determine sources, volume, structure).
    ○ Define requirements (pipeline stages, potential data flow, big data tools to be used).
    
● Prototype & Infrastructure Setup (Weeks 3-5)

    ○ Set up and configure the chosen technologies (Spark, Kafka, databases, etc.).
    ○ Implement the initial data ingestion and storage components.
    ○ Validate the basic end-to-end flow with a small sample of data.
    
● Core Functionality & Analytics (Weeks 6-8)

    ○ Implement the main processing logic (batch or streaming) using Spark/Dask/Flink or a combination thereof.
    ○ If relevant, build the analytics or machine learning models on top of the processed data.
    
● Integration & Demo Preparation (Weeks 9-11)

    ○ Integrate all components into a single cohesive system (mind docker).
    ○ Develop a real-time dashboard or a clear demonstration interface to show results.
    
● Refinement & Final Presentation (Weeks 12+)

    ○ Optimize or refine any pipeline components if time allows.
    ○ Prepare the 10-slide deck and codebase for submission.
    ○ Conduct a live demo (real-time, if applicable) during the oral exam

REMARKS:
● All projects are about designing and implementing big data systems.

● We expect you to use big data technologies that you learned throughout the course
(you could solve the problem without BDT, but this wouldn’t lead to a decent score).

● We welcome (and reward) projects that use creative, non-trivial approaches to the
problems at hand.

● For each project, you have to identify potentially relevant input data (and sources
thereof).

● We suggest you to consider potential (real) data sources, to better understand the
challenges of what happens ‘in the wild’ and to make the problem more concrete.
Real data is great, but in case this is not feasible (for reasons to be explained within
the project report), consider building synthetic (yet realistic-looking) datasets.
Consider checking Kaggle, HuggingFace or similar platforms for relevant datasets.

● Data exploration and design is something you can start working on right away. For
the implementation part, there may be relevant technologies that you still have to
see in class (so don’t hurry coding right away, first think, then act).

● Demos (with real data whenever possible) are highly appreciated.

● Remember that you can swap projects among teams - just get an agreement no
later than 24/4 EOB and inform us by email (with all team members involved in CC).

● You have details about the report (10 slides) and how to share the code.

● Last, but not least: projects include details such as potential approaches,
metrics, functionality etc. These are just suggestions, do not consider them
as mandatory
