# Project Startup Guide

This project analyzes stock market trends in real time by combining financial data, macroeconomic indicators, and sentiment analysis from news and social media. The goal is to **provide a one-minute-ahead forecast of each company's stock price**, displayed on an interactive dashboard, which also allows real-time monitoring of market price anomalies.
This repository provides two Docker Compose configurations to launch the Stock Market Trend Analysis project:

- **Initial setup** involving historical data download and model training.

- **Continuous streaming** with a pre-trained model that also supports real-time retraining.

### Prerequisites

To start and use the project, ensure you have **Docker** installed on your system. Furthermore, it is essential that Docker is configured with the following minimum resources:
- **RAM**: Minimum 8 GB RAM (allocated to Docker)
- **CPU**: Minimum 12 CPUs (allocated to Docker)

### Essential Setup

**1. Clone the repository**

First, clone this repository to your local system using the repository url: https://github.com/elisa-negrini/BDT-project.git

**2. Download of the .env file**

Download the provided .env file and place it in the root directory of this repository. This file will contain necessary credentials and configuration settings.

**3. Alpaca Credentials**

To use real stock market streaming and historical data, you need to configure your Alpaca credentials. You can obtain an **API_KEY_ALPACA** and an **API_SECRET_ALPACA** by registering through the Alpaca Trading API: https://alpaca.markets/. Alternatively, you can send an email to samuele.viola@studenti.unitn.it to receive updated credentials.

Once obtained, modify the environment variables in the .env file with your credentials (**API_KEY_ALPACA** and **API_SECRET_ALPACA**).

#### NOTE: Stock Market Data Availability

The Alpaca (stock market) streaming data is real and is provided Monday to Friday from 9:30 AM to 4:00 PM (US Eastern Time, ET), which corresponds to **3:30 PM to 10:00 PM (Italian Summer Time, CEST)**. For the rest of the time, synthetic data will be generated to maintain the flow, and therefore, it is not necessary to have updated **API_KEY_ALPACA** and **API_SECRET_ALPACA**. The other data streams (macroeconomics data, company fundamentals, bluesky’s sentiment and news’ bluesky) are always real.

## 1. Docker Compose for Streaming (docker-compose-stream.yml)

This configuration is designed to start the real-time data stream and use an already trained model for prediction. It's the ideal option for those who want to see the project in action without having to manage the initial model training.

#### Startup

To start only the streaming data flow and prediction, run the following command in your terminal:

<pre lang="markdown"> docker-compose -f docker-compose-stream.yml up --build -d </pre>

#### Dashboard Visualization

After launching the streaming configuration, you can access the dashboard at http://localhost:8501.
From the dropdown menu at the top, you can select a company and view both the stock price trend and the future prediction generated by the model, along with the real-time detection of potential market anomalies.

## 2. Docker Compose for Historical Data and Training (docker-compose-historical.yml)

This comprehensive setup first **downloads approximately 13 million rows of historical data (~4GB) and trains the model from scratch**. Once this initial training is complete, you will manually transition to a continuous streaming mode with real-time model retraining enabled. This provides a more realistic setup for an evolving model.

The first prediction will typically be available about 5 minutes after the dashboard starts, after which it will continue continuously with ongoing retraining.

#### Startup

To download historical data, perform initial model training, and then start continuous streaming with retraining, follow these steps:

1. **Start the historical data download and initial training:**

<pre lang="markdown"> docker-compose -f docker-compose-historical.yml up --build -d </pre>

Monitor the container logs (docker-compose logs -f) to determine when the initial training process has finished. This process can take a significant amount of time depending on your system's resources and data volume.

2. **Once initial training is complete, shut down the docker-compose-historical.yml configuration:**

<pre lang="markdown"> docker-compose -f docker-compose-historical.yml down </pre>

It is crucial to perform this shutdown to release resources and prepare for the next step.

3. **Start the continuous streaming with retraining:**

<pre lang="markdown"> docker-compose -f docker-compose-retrain.yml up --build -d </pre>

This will launch the application in a mode where it streams real-time data and continuously retrains the model using the historical data you've already downloaded.

#### Dashboard Visualization

Once the streaming configuration is launched, you can access the dashboard at http://localhost:8501. From the dropdown menu, you can select a company to view its stock price trend, the model's future prediction, and real-time detection of potential market anomalies.

### Company Configuration

The project considers a specific set of companies. You can modify these companies by customizing the companies_info.csv file located in the postgres/ folder. If you want to change the companies to be considered in the project, it is **necessary** to restart docker-compose-historical.yml to re-download the historical data and retrain the models on the new companies. You can choose from all the companies listed on the New York Stock Exchange (NYSE) and NASDAQ.

Additionally, **you must remove the persistent PostgreSQL volume** that stores previous company data. Otherwise, the changes will not take effect.
Run the following command before restarting the configuration:

<pre lang="markdown"> docker volume rm bdt-project_pgdata </pre>

**Important**: With Alpaca's free API plan, you cannot exceed 30 companies.

In the companies_info.csv file:
- Modify the **"ticker_id"** column with a unique identification number.
- Modify the **"ticker"** column with the ticker of the company you wish to add.
- Modify the **"company_name"** column with the full company name (this name will appear in the dashboard and will be used for sentiment searches).
- Use the **"related_words"** column to add a second keyword to search for that company (e.g., a company nickname or a closely related term, like "Facebook" for "META").
- Set **"is_active"** to TRUE or FALSE to include or exclude a company from the project.

After modifying and saving the companies_info.csv file, you need to update the fundamental data for the companies. To do this, run the following command:

<pre lang="markdown"> docker exec -it app python company_fundamentals.py </pre>

**API Limits for Fundamental Data**: The API for fundamental data has a limit of 250 requests per day. Each company requires 3 API calls. Therefore, you cannot modify the full set of 30 companies more than 2 times on the same day.

### Managing Docker Compose

#### Shutting Down a Docker Compose

To shut down any Docker Compose configuration, use the command:

<pre lang="markdown"> docker-compose -f docker-compose-filename.yml down </pre>

For example, to shut down the historical configuration:

<pre lang="markdown"> docker-compose -f docker-compose-historical.yml down </pre>
